{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a7dc9a-24e4-46ca-a2cc-5d8a1b3ba39d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import os\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "\n",
    "import sys\n",
    "import config\n",
    "\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "sys.path.append('model_building/create_image_folders.py')\n",
    "from model_building.create_image_folders import * \n",
    "sys.path.append('model_building/cnn_model_keras.py')\n",
    "from model_building.cnn_model_keras import *\n",
    "sys.path.append('model_building/new_keras_model.py')\n",
    "from model_building.new_keras_model import *\n",
    "sys.path.append('model_test/test_model.py')\n",
    "from model_test.test_model import *\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\", UserWarning)\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b6b9a18-3628-4eb2-908e-91f210401e29",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88918cb2-3777-4b13-8d57-8894cb4987a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Set paths\n",
    "img_folder = os.path.join(os.getcwd(),\"data\",\"ai_ready\",\"images\")\n",
    "train_img = os.path.join(os.getcwd(),\"data\",\"ai_ready\",\"train_images\")\n",
    "val_img = os.path.join(os.getcwd(),\"data\",\"ai_ready\",\"val_images\")\n",
    "test_img = os.path.join(os.getcwd(),\"data\",\"ai_ready\",\"test_images\")\n",
    "labels_image = os.path.join(os.getcwd(),\"data\",\"ai_ready\",\"x-ai_data.csv\")\n",
    "create_images =False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "102801e9-5f01-4cb4-bec7-9e7f9ba2e42c",
   "metadata": {},
   "source": [
    "## Create Subfolder"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6da17ccb",
   "metadata": {},
   "source": [
    "Use the fonction \"subfolders\" to do the same thing as the cells below, DO NOT run it twice to avoid duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72f1bdb-ad89-451a-8721-83615ae0b891",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_image = pd.read_csv(labels_image)\n",
    "train = labels_image.loc[labels_image['split']=='train']\n",
    "val = labels_image.loc[labels_image['split']=='validation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81d57c63-4fa7-4757-ae53-288c7c764b0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train0 = train.loc[train['class']==0]\n",
    "train1 = train.loc[train['class']==1]\n",
    "\n",
    "val0 = val.loc[val['class']==0]\n",
    "val1 = val.loc[val['class']==1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4907e31e-9792-45e1-912d-d26e435437ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move TRAIN images labeled 0 to the correct folder\n",
    "\n",
    "for i in train0.index:\n",
    "    im = cv2.imread(img_folder+train0.loc[i,'filename'])\n",
    "    cv2.imwrite(train_img + '0/' +train0.loc[i,'filename'], im)\n",
    "#Move TRAIN images labeled 1 to the correct folder\n",
    "for i in train1.index:\n",
    "    im = cv2.imread(img_folder+train1.loc[i,'filename'])\n",
    "    cv2.imwrite(train_img+'1/' +train1.loc[i,'filename'], im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072867bb-f74a-4512-b0c6-b3f7dc18b5bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move val images labeled 0 to the correct folder\n",
    "for i in val0.index:\n",
    "    im = cv2.imread(img_folder+val0.loc[i,'filename'])\n",
    "    cv2.imwrite(val_img + '0/' +val0.loc[i,'filename'], im)\n",
    "#Move val images labeled 1 to the correct folder\n",
    "for i in val1.index:\n",
    "    im = cv2.imread(img_folder+val1.loc[i,'filename'])\n",
    "    cv2.imwrite(val_img+'1/' +val1.loc[i,'filename'], im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7f5a94-bc57-47ce-aba3-89e4bf098815",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in train0.index:\n",
    "#     try:\n",
    "\n",
    "#         im = cv2.imread(os.path.join(img_folder, train0.loc[i, \"filename\"]))\n",
    "#         cv2.imwrite(os.path.join(train_img, \"0\", train0.loc[i, \"filename\"]), im)\n",
    "#     except:\n",
    "#         ipdb.set_trace()\n",
    "# # Move TRAIN images labeled 1 to the correct folder\n",
    "# for i in train1.index:\n",
    "#     im = cv2.imread(os.path.join(img_folder, train1.loc[i, \"filename\"]))\n",
    "#     cv2.imwrite(os.path.join(train_img, \"1\", train1.loc[i, \"filename\"]), im)\n",
    "\n",
    "# for i in val0.index:\n",
    "#     im = cv2.imread(os.path.join(img_folder, val0.loc[i, \"filename\"]))\n",
    "#     cv2.imwrite(os.path.join(val_img, \"0\", val0.loc[i, \"filename\"]), im)\n",
    "\n",
    "# # Move TRAIN images labeled 1 to the correct folder\n",
    "# for i in val1.index:\n",
    "#     im = cv2.imread(os.path.join(img_folder, val1.loc[i, \"filename\"]))\n",
    "#     cv2.imwrite(os.path.join(val_img, \"1\", val.loc[i, \"filename\"]), im)\n",
    "\n",
    "# # Remove hidden file\n",
    "# try:\n",
    "#     shutil.rmtree(\"image/train/.ipynb_checkpoints\")\n",
    "#     shutil.rmtree(\"image/val/.ipynb_checkpoints\")\n",
    "# except:\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d20ec78c-a0d0-4087-b55e-2e62f8721e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "\n",
    "# #Remove hidden file\n",
    "# shutil.rmtree(\"image/train/.ipynb_checkpoints\")\n",
    "# shutil.rmtree(\"image/val/.ipynb_checkpoints\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04342dc-aaf4-4080-95eb-d9b17535ac88",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d239954-82a8-41be-99df-59c49ef5e995",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train and Val dataset\n",
    "tf.config.list_physical_devices()\n",
    "print(\"Num GPUs Available: \", len(tf.config.list_physical_devices(\"GPU\")))\n",
    "physical_devices = tf.config.list_physical_devices(\"GPU\")\n",
    "if len(physical_devices) > 0:\n",
    "    tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "train_ds = train_set(train_img, config.image_size, config.batch_size)\n",
    "val_ds = val_set(val_img, config.image_size, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e678f97c-97a9-484a-a0eb-f3ee0b59550a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c06133-847f-40cd-a951-f3a3bcb5c820",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 10))\n",
    "# for images, labels in train_ds.__getitem__(3):\n",
    "images, labels = train_ds.__getitem__(1)\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(images[i])\n",
    "    plt.title(int(labels[i]))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c3ba38-785c-4bbf-a415-ec82cb0057c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Model\n",
    "model = make_model(input_shape=config.image_size + (3,), num_classes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "089a425d-73d4-440d-a71a-e158b8c0a6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_model(model, train_ds, val_ds, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8faf7c30-6672-453c-8d44-e1f229dd99a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130a03c1-b31e-4f3a-a01c-1c737fe547e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualize data augmentation\n",
    "data_augmentation = keras.Sequential(\n",
    "    [\n",
    "        layers.RandomFlip(\"horizontal_and_vertical\"),\n",
    "        layers.RandomRotation(0.1),\n",
    "        layers.RandomContrast([0,1]),\n",
    "        layers.RandomTranslation(height_factor=0.2, width_factor=0.2)\n",
    "    ]\n",
    ")\n",
    "plt.figure(figsize=(10, 10))\n",
    "images, _ in train_ds.__getitem__(4)\n",
    "# for images, _ in train_ds.take(1):\n",
    "for i in range(9):\n",
    "    augmented_images = data_augmentation(images)\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow((255*augmented_images[0].numpy()).astype(\"uint8\"))\n",
    "    plt.axis(\"off\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c95f9e96-bd86-46c1-bcc5-ee24e86f3c4a",
   "metadata": {},
   "source": [
    "## Second Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001df99d-e28b-4ebf-af91-51e6c005158c",
   "metadata": {},
   "outputs": [],
   "source": [
    "test = labels_image.loc[labels_image['split']=='test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c56f3492-7224-498d-a9fe-b13d20bd8954",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3483a22-667b-42d0-b365-e9e0bec342f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Move TEST images to the correct folder, only run once: create a test folder with another test folder with all the images inside\n",
    "for i in test.index:\n",
    "    im = cv2.imread(os.path.join(img_folder,test.loc[i,'filename']))\n",
    "    # cv2.imwrite(test_img + 'test/' + test.loc[i,'filename'], im)\n",
    "    # im = cv2.imread(os.path.join(img_folder, val1.loc[i, \"filename\"]))\n",
    "    cv2.imwrite(os.path.join(test_img, \"test\", test.loc[i, \"filename\"]), im)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03e581e9-cc89-445e-b354-e7c67ff0706b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import shutil\n",
    "# shutil.rmtree(os.path.join(test_img, \"test\",\".ipynb_checkpoints\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68930ac9-b27f-4e9e-9af4-d74371b6abc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f597b3d-cbf2-4b70-9900-86d3d26312b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from numpy import expand_dims\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from matplotlib import pyplot\n",
    "from tensorflow.keras.preprocessing.image import load_img\n",
    "from tensorflow.keras.preprocessing.image import img_to_array\n",
    "\n",
    "image = load_img(os.path.join(img_folder,'silos_256-0-0--6-16-536-28464.png'))\n",
    "image = img_to_array(image).astype(int)\n",
    "data = np.expand_dims(image, 0)\n",
    "\n",
    "# Calling ImageDataGenerator for creating data augmentation generator.\n",
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=90,\n",
    "    shear_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    vertical_flip=True,\n",
    "    # brightness_range = [0.5, 2.0],\n",
    "    zca_whitening =True,\n",
    "    # zoom_range=0.3\n",
    ")\n",
    "\n",
    "# Creating an iterator for data augmentation\n",
    "it = datagen.flow(data, batch_size=1)\n",
    "\n",
    "# Preparing the Samples and Plot for displaying output\n",
    "for i in range(9):\n",
    "    # preparing the subplot\n",
    "    pyplot.subplot(330 + 1 + i)\n",
    "    # generating images in batches\n",
    "    batch = it.next()\n",
    "    # Remember to convert these images to unsigned integers for viewing \n",
    "    image = batch[0].astype('uint8')\n",
    "    # Plotting the data\n",
    "    pyplot.imshow(image)\n",
    "\n",
    "pyplot.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f487b76-95d2-41fb-aa8e-a81f6105b399",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_set(train_path, image_size, batch_size):\n",
    "    \"\"\"\n",
    "    Create train dataset to train the model\n",
    "    Input:\n",
    "        train_path: path referring to where the train images are stored\n",
    "        image_size: size of the images\n",
    "        batch_size: batch size\n",
    "    Output:\n",
    "        train_generator: train set in Keras format\n",
    "    \"\"\"\n",
    "    train_datagen = ImageDataGenerator(\n",
    "        rescale=1. / 255,\n",
    "        shear_range=0.2,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "        zca_whitening =True,\n",
    "        # brightness_range = [0.5, 2.0]\n",
    "    )\n",
    "\n",
    "    train_generator = train_datagen.flow_from_directory(\n",
    "        train_path, target_size=image_size, batch_size=batch_size, class_mode=\"binary\"\n",
    "    )\n",
    "\n",
    "    return train_generator\n",
    "\n",
    "\n",
    "def val_set(val_path, image_size, batch_size):\n",
    "    \"\"\"\n",
    "    Create val dataset to train the model\n",
    "    Input:\n",
    "        val_path: path referring to where the val images are stored\n",
    "        image_size: size of the images\n",
    "        batch_size: batch size\n",
    "    Output:\n",
    "        val_generator: train set in Keras format\n",
    "    \"\"\"\n",
    "    test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "    val_generator = test_datagen.flow_from_directory(\n",
    "        val_path, target_size=image_size, batch_size=batch_size, class_mode=\"binary\"\n",
    "    )\n",
    "\n",
    "    return val_generator\n",
    "\n",
    "\n",
    "def test_set(test_path, image_size, batch_size):\n",
    "    \"\"\"\n",
    "    Create test dataset to test the model\n",
    "    Input:\n",
    "        test_path: path referring to where the test images are stored\n",
    "        image_size: size of the images\n",
    "        batch_size: batch size\n",
    "    Output:\n",
    "        test_generator: test set in Keras format\n",
    "    \"\"\"\n",
    "    test_datagen = ImageDataGenerator(rescale=1.0 / 255)\n",
    "\n",
    "    test_generator = test_datagen.flow_from_directory(\n",
    "        test_path,\n",
    "        target_size=image_size,\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False,\n",
    "    )\n",
    "\n",
    "    return test_generator\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88621a80-d503-4c9a-bbdd-85e1d3f40c4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Train, Val, and Test dataset\n",
    "train_generator = train_set(train_img, config.image_size, config.batch_size)\n",
    "val_generator = val_set(val_img, config.image_size, config.batch_size)\n",
    "test_generator = test_set(test_img, config.image_size, config.batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16e90bf5-ab49-4df2-991d-874920dca2b7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## Model\n",
    "model = keras_model(config.input_shape, train_generator, val_generator, config.batch_size, 2, 'keras_model2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa2f5e2-20dc-4b97-9124-b6417dea8857",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# config.input_shape, train_generator, val_generator, config.batch_size, config.number_epochs\n",
    "model = Sequential()\n",
    "model.add(Conv2D(64, (2, 2), input_shape=(256,256,3)))\n",
    "model.add(LeakyReLU(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(LeakyReLU(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (2, 2)))\n",
    "model.add(LeakyReLU(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(LeakyReLU(0.2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(64))\n",
    "model.add(LeakyReLU(0.2))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],)\n",
    "\n",
    "model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=1400 // config.batch_size,\n",
    "    epochs=25,\n",
    "    validation_data=val_generator,\n",
    "    validation_steps=400 // config.batch_size,\n",
    ")\n",
    "\n",
    "model.save(\"keras_model2\" + \".h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2218c613-d06b-4921-a8b5-0b355761aad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_keras = load_model(\"keras_model2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150c617d-3db4-4358-825d-e6ea696b200d",
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = test_model(test_generator, model_keras, config.batch_size)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "558438cb-2cc0-4015-8107-44fe379a25d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_preds(preds, train_generator, test_generator, 'keras_model2_preds')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beeea08f-ebc8-4e8f-910c-90469c68767c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6089c54-7746-44d8-aecc-b4586d7a3b6b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "c4b1a4a749a8d48ef741ed32095ab3a7e8b65ab1c4196700a52abd92786a361c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
